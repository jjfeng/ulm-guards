# Phytolith data analysis

import os

from os.path import join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption
import numpy as np

Import('env')
localenv = env.Clone()

nest = SConsWrap(Nest(), localenv['output'], alias_environment=localenv)

TRAIN_DATA = "../data/mnist/mnist_train_pca.pkl"
TEST_DATA = "../data/mnist/mnist_test_pca.pkl"
WEIRD_DATA = "../data/mnist/weird_mnist_test_pca.pkl"
COST_DECLINES = [0.3]
DROPOUT_RATE = 0.1
NUM_ENSEMBLE = 5
NUM_ULM_ITERS = 1
LEARNING_RATE = 0.0005
KFOLDS = 5
FOLD_IDXS = [0]
DO_NO_HARMS = [0.25]

config_dict = {
    "act_func": "relu",
    "parametric_form": "multinomial",
    "density_layer_sizes": "300+60+30",
    "density_weight": [0.001],
    "decision_weight": [0.001],
    "weight_penalty_type": "ridge",
    "do_no_harm": [2], #1 0.25 0.06 were all too big
    "log_barrier": [0.0001],
    "support_sim_num": 500,
    "max_iters": 700,
    "num_inits": 1,
}

nest.add(
    'cost_decline',
    COST_DECLINES,
    label_func=lambda c: 'cost_decline%s' % str(c),
)

nest.add_aggregate('aggregate_results', list)
nest.add(
    'seed',
    range(30,50),
    label_func=lambda c: 'model_seed%d' % c,
)

nest.add_aggregate('aggregate_nns', list)
nest.add_aggregate('aggregate_ensemble_nns', list)
nest.add_aggregate('aggregate_ulm_nns', list)
nest.add_aggregate('aggregate_ensemble_ulm_nns', list)

nest.add(
    'fold_idx',
    FOLD_IDXS,
    label_func=lambda c: 'fold_idx%d' % c,
)

@nest.add_target_with_env(localenv)
def split_data(env, outdir, c):
    targets = [
        join(outdir, 'obs_data_split.pkl')]
    cmd = [
        'python create_data_split.py',
        '--seed',
        c['seed'],
        '--k-fold',
        KFOLDS,
        '--fold-idx',
        c['fold_idx'],
        '--in-data-file',
        TRAIN_DATA,
        '--out-file ${TARGETS[0]}']
    return env.Command(
        targets,
        [],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_plain_nns(env, outdir, c):
    targets = [
        join(outdir, 'fit_plain_nn.pkl'),
        join(outdir, 'fit_plain_nn_log.txt')]
    cmd = [
        'srun -p matsen_e,campus,restart --cpus-per-task 4',
        'python fit_density_nn.py',
        '--seed',
        50 + int(c['fold_idx'] * 40),
        '--data-file',
        TRAIN_DATA,
        '--data-split-file ${SOURCES[0]}',
        '--density-parametric-form',
        config_dict["parametric_form"],
        '--density-layer-sizes',
        config_dict["density_layer_sizes"],
        '--density-weight',
        ",".join(map(str, config_dict["density_weight"])),
        '--weight-penalty-type',
        config_dict['weight_penalty_type'],
        '--act-func',
        config_dict['act_func'],
        '--dropout 0',
        '--cv 3',
        '--num-ensemble 1',
        '--num-init',
        config_dict['num_inits'],
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
	LEARNING_RATE,
        '--do-distributed',
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_ensemble_nns(env, outdir, c):
    targets = [
        join(outdir, 'fit_ensemble_nn.pkl'),
        join(outdir, 'fit_ensemble_nn_log.txt')]
    cmd = [
        'python fit_density_nn.py',
        '--seed',
        50 + int(c['fold_idx'] * 40),
        '--data-file',
        TRAIN_DATA,
        '--data-split-file ${SOURCES[0]}',
        '--density-parametric-form',
        config_dict["parametric_form"],
        '--density-layer-sizes',
        config_dict["density_layer_sizes"],
        '--density-weight',
        ",".join(map(str, config_dict["density_weight"])),
        '--weight-penalty-type',
        config_dict['weight_penalty_type'],
        '--act-func',
        config_dict['act_func'],
        '--dropout 0',
        '--cv 3',
        '--num-ensemble',
        NUM_ENSEMBLE,
        '--num-init',
        config_dict['num_inits'],
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
	LEARNING_RATE,
        '--do-distributed',
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_ensemble_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'],
        ' '.join(map(str, cmd)))

nest.add(
    'do_no_harm',
    DO_NO_HARMS,
    label_func=lambda c: 'do_no_harm%s' % str(c),
)

@nest.add_target_with_env(localenv)
def fit_ensemble_ulm(env, outdir, c):
    targets = [
        join(outdir, 'fit_ensemble_ulm.pkl'),
        join(outdir, 'fit_ensemble_ulm_log.txt')]
    cmd = [
        'python fit_simultaneous_decision_density_nn.py',
        '--seed',
        10 + int(c['fold_idx'] * 4) + int(c['cost_decline'] * 100),
        '--data-file',
        TRAIN_DATA,
        '--data-split-file ${SOURCES[0]}',
        '--density-parametric-form',
        config_dict["parametric_form"],
        '--density-layer-sizes',
        config_dict["density_layer_sizes"],
        '--density-weight-param',
        ",".join(map(str, config_dict["density_weight"])),
        '--decision-weight-param',
        ",".join(map(str, config_dict["decision_weight"])),
        '--log-barrier',
        ",".join(map(str, config_dict["log_barrier"])),
        '--weight-penalty-type',
        config_dict["weight_penalty_type"],
        '--do-no-harm',
        c['do_no_harm'],
        '--cost-decline',
        c['cost_decline'],
        '--num-ensemble',
        NUM_ENSEMBLE,
        '--do-distributed',
        '--act-func',
        config_dict['act_func'],
        '--cv 3',
        '--num-init',
        config_dict['num_inits'],
        '--support-sim-num',
        config_dict['support_sim_num'],
        '--max-iter',
        int(config_dict['max_iters'] * 0.5),
        '--learning-rate',
        LEARNING_RATE,
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_ensemble_ulm_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_neural_networks(env, outdir, c):
    targets = [
        join(outdir, 'fit_ulm_decline_nn.pkl'),
        join(outdir, 'fit_ulm_decline_nn_log.txt')]
    cmd = [
        'srun -p matsen_e,campus --cpus-per-task 4',
        'python fit_simultaneous_decision_density_nn.py',
        '--seed',
        10 + int(c['fold_idx'] * 4) + int(c['cost_decline'] * 100),
        '--data-file',
        TRAIN_DATA,
        '--data-split-file ${SOURCES[0]}',
        '--density-parametric-form',
        config_dict["parametric_form"],
        '--density-layer-sizes',
        config_dict["density_layer_sizes"],
        '--density-weight-param',
        ",".join(map(str, config_dict["density_weight"])),
        '--decision-weight-param',
        ",".join(map(str, config_dict["decision_weight"])),
        '--log-barrier',
        ",".join(map(str, config_dict["log_barrier"])),
        '--weight-penalty-type',
        config_dict["weight_penalty_type"],
        '--do-no-harm',
        #",".join(map(str, config_dict["do_no_harm"])),
        c['do_no_harm'],
        '--cost-decline',
        c['cost_decline'],
        '--act-func',
        config_dict['act_func'],
        '--cv 3',
        '--num-init',
        config_dict['num_inits'],
        '--support-sim-num',
        config_dict['support_sim_num'],
        '--max-iter',
        int(config_dict['max_iters'] * 0.5),
        '--learning-rate',
        LEARNING_RATE,
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_ulm_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'],
        ' '.join(map(str, cmd)))

nest.pop('do_no_harm')
nest.pop('fold_idx')

@nest.add_target_with_env(localenv)
def plot(env, outdir, c):
    targets = [
        join(outdir, 'plot_log.txt'),
        join(outdir, 'results.pkl')]
    sources = [
        c['aggregate_ulm_nns'],
        c['aggregate_ensemble_ulm_nns'],
        c['aggregate_nns'],
        c['aggregate_ensemble_nns'],
    ]
    start_idx = 0
    result_file_names = []
    for model_res in sources:
        num_to_agg = len(model_res)
        result_file_names.append(
            ",".join(["${SOURCES[%d]}" % i for i in range(start_idx, start_idx + num_to_agg)]))
        start_idx += num_to_agg
    cmd = [
        'python plot_mnist_holdout.py',
        '--plain-eps 0.005',
        '--ensemble-eps 0.005',
        '--cost-decline',
        c['cost_decline'],
        '--train-data-file',
        TRAIN_DATA,
        '--test-data-file',
        TEST_DATA,
        '--weird-data-file',
        WEIRD_DATA,
        '--ulm-files',
        result_file_names[0],
        '--ensemble-ulm-files',
        result_file_names[1],
        '--plain-files',
        result_file_names[2],
        '--ensemble-files',
        result_file_names[3],
        '--log-file ${TARGETS[0]}',
        '--out-results ${TARGETS[1]}',
    ]
    c['aggregate_results'].append(targets[1])
    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd)))

nest.pop('seed')

@nest.add_target_with_env(localenv)
def aggregate(env, outdir, c):
    targets = [
        join(outdir, 'plot_log.txt')]
    sources = [
        c['aggregate_results'],
    ]
    start_idx = 0
    result_file_names = []
    for model_res in sources:
        num_to_agg = len(model_res)
        result_file_names.append(
            ",".join(["${SOURCES[%d]}" % i for i in range(start_idx, start_idx + num_to_agg)]))
        start_idx += num_to_agg
    cmd = [
        'python plot_aggregate_results.py',
        '--result-files',
        result_file_names[0],
        '--log-file ${TARGETS[0]}',
    ]
    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd)))
